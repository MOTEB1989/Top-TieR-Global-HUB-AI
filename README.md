# LexCode Hybrid Stack ๐

ููุฏุณุฉ ูุฌููุฉ ูุชููุฉ:
- **Rust (core/):** ูุญุฑู ุงูุฃุฏุงุก ูุงูุฎุฏูุงุช ุงูุฃุณุงุณูุฉ (HTTP/axum).
- **Node.js + TypeScript (services/api/):** ุจูุงุจุฉ APIุ ูุตุงุฏูุฉุ ุชูุญูุฏ ุงููุฒููุฏุงุช.
- **Python (adapters/python/lexhub/):** ูุตูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุจูุงูุงุช (OpenAI/Anthropic/HF/Kaggle...).

## ุงูุชุดุบูู ุงูุณุฑูุน
```bash
cp .env.example .env
docker compose up --build
```
- Rust Core ุนูู `http://localhost:8080`
- API Gateway ุนูู `http://localhost:3000`


## ุงุณุชุฎุฏุงู /v1/ai/infer (OpenAI)
ุถุน ููุชุงุญู ูู `.env`:
```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini  # ุงุฎุชูุงุฑู
OPENAI_BASE_URL=https://api.openai.com/v1  # ุงุฎุชูุงุฑู
```
ุงุฎุชุจุฑ:
```bash
curl -X POST http://localhost:3000/v1/ai/infer \  -H "Content-Type: application/json" \  -d '{ "messages": [ { "role": "user", "content": "ุนุฑูู LexCode ูู ุฌููุฉ ูุงุญุฏุฉ." } ] }'
```

## Runner Service (FastAPI)
ููููุฑ ูุฌููุฏ `runner_service/` ุบูุงููุง ุจุณูุทูุง ุญูู `LexCodeRunner` ุนุจุฑ FastAPI.

### ุจูุงุก ูุชุดุบูู ุงูุญุงููุฉ
```bash
docker build -t myorg/lexcode-runner ./runner_service
docker run -d -p 8000:8000 --name runner myorg/lexcode-runner
```

### ููุงุท ุงูููุงูุฉ
- `GET /health` โ ูุญุต ุงูุตุญุฉ.
- `POST /run` โ ุชุดุบูู ูุตูุฉ YAML ูุจุงุดุฑุฉ ูู ุงูุทูุจ.

ูุซุงู ุงุณุชุฎุฏุงู:
```bash
curl -X POST http://localhost:8000/run \
  -H "Content-Type: application/json" \
  -d '{
    "recipe": {
      "project": "demo",
      "tasks": [
        {
          "id": "t1",
          "name": "Hello World",
          "steps": [
            {"process": {"model": "gpt-3.5-turbo", "prompt": "ุงูุชุจ ุญููุฉ ูุตูุฑุฉ"}}
          ]
        }
      ]
    }
  }'
```
