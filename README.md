# LexCode Hybrid Stack ğŸš€

Ù‡Ù†Ø¯Ø³Ø© Ù‡Ø¬ÙŠÙ†Ø© Ù…ØªÙŠÙ†Ø©:
- **Rust (core/):** Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (HTTP/axum).
- **Node.js + TypeScript (services/api/):** Ø¨ÙˆØ§Ø¨Ø© APIØŒ Ù…ØµØ§Ø¯Ù‚Ø©ØŒ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø²ÙˆÙ‘Ø¯Ø§Øª.
- **Python (adapters/python/lexhub/):** ÙˆØµÙ„Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (OpenAI/Anthropic/HF/Kaggle...).

## Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
```bash
cp .env.example .env
docker compose up --build
```
- Rust Core Ø¹Ù„Ù‰ `http://localhost:8080`
- API Gateway Ø¹Ù„Ù‰ `http://localhost:3000`


## Ø§Ø³ØªØ®Ø¯Ø§Ù… /v1/ai/infer (OpenAI)
Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ ÙÙŠ `.env`:
```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ
OPENAI_BASE_URL=https://api.openai.com/v1  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ
```
Ø§Ø®ØªØ¨Ø±:
```bash
curl -X POST http://localhost:3000/v1/ai/infer \  -H "Content-Type: application/json" \  -d '{ "messages": [ { "role": "user", "content": "Ø¹Ø±Ù‘Ù LexCode ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©." } ] }'
```

## Mobile Chat Access (iPhone)

To run your personal RAG + Phi-3 + Chat UI stack on your laptop and access it from your iPhone:

```bash
./scripts/run_mobile_chat_stack.sh
```

When the script starts, it will print a line similar to:

```text
Open on your iPhone: http://192.168.X.X:8501
```

1. Make sure your iPhone is on the same Wi-Fi network as your laptop.
2. Open Safari (or Chrome) on the iPhone.
3. Type the printed URL exactly as shown.
4. You should see the Streamlit Chat UI connected to your local Gateway and RAG engine.

This stack is for **personal local development only**, not production.
