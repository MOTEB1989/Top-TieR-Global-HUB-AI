# LexCode Hybrid Stack ğŸš€

Ù‡Ù†Ø¯Ø³Ø© Ù‡Ø¬ÙŠÙ†Ø© Ù…ØªÙŠÙ†Ø©:
- **Rust (core/):** Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (HTTP/axum).
- **Node.js + TypeScript (services/api/):** Ø¨ÙˆØ§Ø¨Ø© APIØŒ Ù…ØµØ§Ø¯Ù‚Ø©ØŒ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø²ÙˆÙ‘Ø¯Ø§Øª.
- **Python (adapters/python/lexhub/):** ÙˆØµÙ„Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (OpenAI/Anthropic/HF/Kaggle...).

## Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
```bash
cp .env.example .env
docker compose up --build
```
- Rust Core Ø¹Ù„Ù‰ `http://localhost:8080`
- API Gateway Ø¹Ù„Ù‰ `http://localhost:3000`


## Ø§Ø³ØªØ®Ø¯Ø§Ù… /v1/ai/infer (OpenAI)
Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ ÙÙŠ `.env`:
```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ
OPENAI_BASE_URL=https://api.openai.com/v1  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ
```
Ø§Ø®ØªØ¨Ø±:
```bash
curl -X POST http://localhost:3000/v1/ai/infer \  -H "Content-Type: application/json" \  -d '{ "messages": [ { "role": "user", "content": "Ø¹Ø±Ù‘Ù LexCode ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©." } ] }'
```

## ğŸ” Telegram Bot with RAG (Retrieval-Augmented Generation)
### Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ø²Ø² Ù„Ù„ØªÙˆÙ„ÙŠØ¯

The Telegram bot now includes RAG capabilities for intelligent code search and context-aware responses.

**Features:**
- **Vector Search**: Search repository files using semantic similarity
- **Auto Context Injection**: Automatically inject relevant code context into chat responses
- **CLI Search Tool**: Query the embeddings index from command line

**Environment Variables:**

| Variable | Default | Purpose |
|----------|---------|---------|
| `ENABLE_RAG` | `false` | Master switch for RAG context injection in `/chat` |
| `EMBEDDING_MODEL` | `text-embedding-3-small` | OpenAI embedding model name |
| `EMBEDDING_INDEX_PATH` | `analysis/embeddings/index.json` | Location of saved embeddings index |
| `EMBEDDING_CHUNK_SIZE` | `1200` | Characters per chunk |
| `EMBEDDING_CHUNK_OVERLAP` | `150` | Overlap characters between chunks |
| `FILE_EXT_ALLOWLIST` | `.py,.ts,.md,.sh,.yaml,.yml,.txt,.json` | Allowed file extensions |
| `EMBEDDING_MAX_FILES` | `0` | Optional limit (# of files); 0 = unlimited |
| `VECTOR_TOP_K` | `6` | Number of top chunks retrieved |

**Bot Commands:**
- `/search <query>` - Search repository files using vector similarity
- `/chat <message>` - Chat with automatic context injection (when `ENABLE_RAG=true`)
- `/status` - View RAG configuration status

**CLI Tools:**
```bash
# Build embeddings index (automatically run on Railway deploy)
python scripts/embed_index.py

# Search index from command line
python scripts/embed_search.py "authentication implementation"
```

**Example Configuration:**
```bash
# Enable RAG in .env
ENABLE_RAG=true
EMBEDDING_MODEL=text-embedding-3-small
VECTOR_TOP_K=6
```

**Arabic / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:**

ÙŠØªØ¶Ù…Ù† Ø¨ÙˆØª ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ø¢Ù† Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª RAG Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„ÙˆØ§Ø¹ÙŠØ© Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚.

**Ø§Ù„Ø£ÙˆØ§Ù…Ø±:**
- `/search <Ø§Ø³ØªØ¹Ù„Ø§Ù…>` - Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…ØªØ¬Ù‡
- `/chat <Ø±Ø³Ø§Ù„Ø©>` - Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø­Ù‚Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ø¹Ù†Ø¯ ØªÙØ¹ÙŠÙ„ `ENABLE_RAG=true`)
- `/status` - Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© ØªÙƒÙˆÙŠÙ† RAG
