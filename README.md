# Top-TieR Global HUB AI ğŸš€

**Enterprise-grade AI orchestration platform with hybrid architecture**

## ğŸ—ï¸ Architecture

| Service | Technology | Port | Purpose |
|---------|------------|------|---------|
| **Core Engine** | Rust (Axum) | 8080 | High-performance embedding & utilities |
| **API Gateway** | Node.js + TypeScript | 3000 | Unified API & provider routing |
| **AI Adapters** | Python (FastAPI) | 8000 | Multi-provider AI integration |

## âœ¨ Features

- ğŸ¤– **Multi-Provider Support**: OpenAI, Anthropic, Hugging Face, local models
- âš¡ **High Performance**: Rust core for compute-intensive operations
- ğŸ” **Secure**: Environment-based secrets, no hardcoded credentials
- ğŸ³ **Docker-Ready**: Full docker-compose orchestration
- â˜¸ï¸ **Kubernetes-Ready**: Health & readiness probes included

## ğŸš€ Quick Start

```bash
# 1. Clone repository
git clone https://github.com/MOTEB1989/Top-TieR-Global-HUB-AI.git
cd Top-TieR-Global-HUB-AI

# 2. Setup environment
cp .env.example .env
# Edit .env with your API keys

# 3. Start services
docker compose up --build

# 4. Test
curl http://localhost:3000/v1/health
```

## ğŸ“¡ API Endpoints

### Health Checks
- `GET /health` - Service health status (Rust core)
- `GET /ready` - Readiness probe for Kubernetes (Rust core)
- `GET /v1/health` - Gateway health status (Node gateway)
- `GET /v1/ready` - Gateway readiness probe (Node gateway)

### AI Inference
```bash
curl -X POST http://localhost:3000/v1/ai/infer \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello, AI!"}
    ],
    "model": "gpt-4o-mini"
  }'
```

### Embeddings
```bash
curl -X POST http://localhost:8080/embed \
  -H "Content-Type: application/json" \
  -d '{"text": "Sample text for embedding"}'
```

## âš™ï¸ Configuration

### Environment Variables (.env)
```env
# AI Providers
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
ANTHROPIC_API_KEY=sk-ant-...

# Database
NEO4J_PASSWORD=secure_password

# Service Ports
RUST_CORE_PORT=8080
NODE_GATEWAY_PORT=3000
PYTHON_ADAPTERS_PORT=8000
```

## ğŸ“ Project Structure

```
Top-TieR-Global-HUB-AI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ rust-core/          # High-performance core
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ main.rs
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ node-gateway/       # API Gateway
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ ai.ts
â”‚   â”‚   â”œâ”€â”€ openai.ts
â”‚   â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ python-adapters/    # AI Integrations
â”‚       â”œâ”€â”€ providers.py
â”‚       â”œâ”€â”€ gpt_client.py
â”‚       â”œâ”€â”€ committee_service.py
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ§ª Testing

```bash
# Test individual services
docker compose up rust-core
docker compose up node-gateway

# View logs
docker compose logs -f

# Run health checks
curl http://localhost:8080/health
curl http://localhost:8080/ready
curl http://localhost:3000/v1/health
curl http://localhost:3000/v1/ready
```

## ğŸ“Š Monitoring

All services include health and readiness probes:
- **Liveness**: `/health` - Is the service alive?
- **Readiness**: `/ready` - Can it handle traffic?

## ğŸ› ï¸ Development

### Build Rust Core
```bash
cd backend/rust-core
cargo build --release
cargo run
```

### Build Node Gateway
```bash
cd backend/node-gateway
npm install
npm run dev
```

### Build Python Adapters
```bash
cd backend/python-adapters
pip install -r requirements.txt
uvicorn committee_service:app --reload
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Built with â¤ï¸ by MOTEB1989**
