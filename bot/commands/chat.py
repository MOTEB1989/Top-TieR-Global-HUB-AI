#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
chat.py

Chat command and fallback text message handler.
Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†ØµÙŠØ©.
"""

import logging
from telegram import Update
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)


async def process_chat_message(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_message: str
) -> None:
    """
    Process a chat message through the AI pipeline.
    
    Args:
        update: Telegram update
        context: Bot context
        user_message: User's message text
    """
    user_id = update.effective_user.id
    
    # Get components from bot_data
    bot_data = context.bot_data
    session_store = bot_data.get("session_store")
    rate_limiter = bot_data.get("rate_limiter")
    safety_filter = bot_data.get("safety_filter")
    response_builder = bot_data.get("response_builder")
    persona_manager = bot_data.get("persona_manager")
    
    # Check rate limit
    if rate_limiter and not rate_limiter.check_limit(user_id):
        remaining_time = rate_limiter.get_reset_time(user_id)
        minutes = remaining_time // 60
        await update.message.reply_text(
            f"â±ï¸ **ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„**\n\n"
            f"Ù„Ù‚Ø¯ ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ ({rate_limiter.max_messages} Ø±Ø³Ø§Ù„Ø© ÙƒÙ„ {rate_limiter.window_seconds // 60} Ø¯Ù‚ÙŠÙ‚Ø©).\n"
            f"Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {minutes} Ø¯Ù‚ÙŠÙ‚Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹."
        )
        logger.warning(f"[bot] user={user_id} rate_limited")
        return
    
    # Safety check
    if safety_filter:
        is_safe, warning, detected = safety_filter.filter_input(user_message)
        if not is_safe:
            await update.message.reply_markdown(warning)
            logger.warning(f"[bot] user={user_id} unsafe_input detected={detected}")
            return
    
    # Get current session
    current_session = context.user_data.get("current_session", "default")
    
    # Get session metadata
    if session_store:
        provider = session_store.get_metadata(user_id, current_session, "provider", "openai")
        model = session_store.get_metadata(user_id, current_session, "model", "gpt-4o-mini")
        persona = session_store.get_metadata(user_id, current_session, "persona", "default")
    else:
        provider = context.user_data.get("provider", "openai")
        model = context.user_data.get("model", "gpt-4o-mini")
        persona = context.user_data.get("persona", "default")
    
    # Get AI client
    client_map = {
        "openai": bot_data.get("openai_client"),
        "anthropic": bot_data.get("anthropic_client"),
        "groq": bot_data.get("groq_client")
    }
    
    client = client_map.get(provider)
    
    if not client or not client.is_available():
        await update.message.reply_text(
            f"âŒ Ø§Ù„Ù…ÙˆÙØ± '{provider}' ØºÙŠØ± Ù…Ù‡ÙŠØ£.\n"
            "Ø§Ø³ØªØ®Ø¯Ù… /provider list Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…ÙˆÙØ±ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­ÙŠÙ†."
        )
        logger.error(f"[bot] user={user_id} provider={provider} unavailable")
        return
    
    # Save user message to session
    if session_store:
        session_store.append_message(user_id, current_session, "user", user_message)
    
    # Build messages for API
    messages = []
    
    # Add system prompt
    if persona_manager:
        system_prompt = persona_manager.get_system_prompt(persona)
        messages.append({"role": "system", "content": system_prompt})
    
    # Add conversation history
    if session_store:
        history = session_store.get_messages(user_id, current_session)
        messages.extend(history)
    else:
        messages.append({"role": "user", "content": user_message})
    
    # Call AI
    try:
        # Send "typing" indicator
        await update.message.chat.send_action("typing")
        
        response = client.chat_completion(
            messages=messages,
            model=model,
            temperature=0.7,
            max_tokens=1000
        )
        
        # Save assistant response
        if session_store:
            session_store.append_message(user_id, current_session, "assistant", response)
        
        # Add follow-up suggestions
        if response_builder:
            response = response_builder.add_suggestions(response)
        
        # Truncate if needed
        if response_builder:
            response = response_builder.truncate_if_needed(response, max_length=4000)
        
        # Record message for rate limiting
        if rate_limiter:
            rate_limiter.record_message(user_id)
        
        # Send response
        await update.message.reply_text(response)
        
        # Log with token approximation
        approx_tokens = len(user_message + response) // 4
        logger.info(
            f"[bot] user={user_id} cmd=chat session={current_session} "
            f"provider={provider} model={model} tokens_approx={approx_tokens}"
        )
        
    except Exception as e:
        error_msg = str(e)
        
        if response_builder:
            error_msg = response_builder.format_error(error_msg)
        
        await update.message.reply_text(error_msg)
        logger.error(f"[bot] user={user_id} chat_error: {e}")


async def cmd_chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /chat command."""
    if not context.args:
        await update.message.reply_text(
            "âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø±Ø³Ø§Ù„ØªÙƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±.\n"
            "Ù…Ø«Ø§Ù„:\n"
            "/chat Ù…Ø§ Ù‡ÙŠ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ù„Ù„Ø£Ù…Ø§Ù† ÙÙŠ APIØŸ\n\n"
            "ðŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ø§Ù‹ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ù†ØµÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… /chat"
        )
        return
    
    user_message = " ".join(context.args).strip()
    await process_chat_message(update, context, user_message)


async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle plain text messages (fallback)."""
    text = update.message.text or ""
    
    if not text.strip():
        return
    
    # Process as chat message
    await process_chat_message(update, context, text.strip())
