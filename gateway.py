#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""AI Gateway V3

â€¢ Multi-provider: OpenAI / Groq / Azure / Local
â€¢ Multi-task per file: code_review / legal / medical / tech / banking / document
â€¢ Multi-file-type: txt / md / py / rs / js / ts / yaml / yml / docx / pdf
â€¢ Output: Markdown Ù…Ù‡ÙŠØ£ Ù„Ù„Ø¯Ù…Ø¬ ÙÙŠ ØªÙ‚Ø§Ø±ÙŠØ± Ø£Ùˆ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Pull Requests
"""

# This script is a standalone CLI tool.
# It is NOT imported by the main application code (gateway/ package is still the programmatic entrypoint).
# It is meant for CI/PR automation and local file review.

from __future__ import annotations

import argparse
import os
from pathlib import Path
from typing import Dict, List

import requests

try:
    from docx import Document  # type: ignore  # Ù„Ù‚Ø±Ø§Ø¡Ø© DOCX
except ImportError:
    Document = None  # type: ignore

try:
    from PyPDF2 import PdfReader  # type: ignore  # Ù„Ù‚Ø±Ø§Ø¡Ø© PDF
except ImportError:
    PdfReader = None  # type: ignore

# â€”â€“ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù€ Prompts â€”â€“

BASE_DIR = Path(__file__).parent
PROMPTS_DIR = BASE_DIR / "ai_prompts"

TASK_PROMPTS: Dict[str, str] = {
    "code_review": "review_code.txt",
    "legal": "legal_analysis.txt",
    "medical": "medical_info.txt",
    "tech": "tech_trends.txt",
    "banking": "banking_compliance.txt",
    "document": "document_analysis.txt",
}


def load_prompt(task: str) -> str:
    """ØªØ­Ù…ÙŠÙ„ Ù†Øµ Ø§Ù„Ù€ prompt Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ù‡Ù…Ø©."""

    if task not in TASK_PROMPTS:
        raise ValueError(f"Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©: {task}")

    path = PROMPTS_DIR / TASK_PROMPTS[task]
    if not path.is_file():
        raise FileNotFoundError(f"Ù…Ù„Ù Ø§Ù„Ù€prompt ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path}")

    return path.read_text(encoding="utf-8")


# â€”â€“ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© â€”â€“


def read_text_file(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="ignore")


def read_docx_file(path: Path) -> str:
    if Document is None:
        raise RuntimeError("Ø§Ù„Ø­Ø²Ù…Ø© python-docx ØºÙŠØ± Ù…Ø«Ø¨ØªØ© (Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© DOCX).")

    doc = Document(str(path))
    return "\n".join(p.text for p in doc.paragraphs)


def read_pdf_file(path: Path) -> str:
    if PdfReader is None:
        raise RuntimeError("Ø§Ù„Ø­Ø²Ù…Ø© PyPDF2 ØºÙŠØ± Ù…Ø«Ø¨ØªØ© (Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© PDF).")

    reader = PdfReader(str(path))
    texts: List[str] = []
    for page in reader.pages:
        txt = page.extract_text() or ""
        texts.append(txt)
    return "\n".join(texts)


def read_file_smart(path_str: str) -> str:
    """Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø­Ø³Ø¨ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯."""

    path = Path(path_str)
    if not path.is_file():
        raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path_str}")

    suffix = path.suffix.lower()
    if suffix == ".docx":
        return read_docx_file(path)
    if suffix == ".pdf":
        return read_pdf_file(path)

    return read_text_file(path)


# â€”â€“ ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ â€”â€“


def guess_task_from_path(path_str: str) -> str:
    """ØªØ®Ù…ÙŠÙ† Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±/Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯."""

    p = Path(path_str)
    suffix = p.suffix.lower()
    parts = p.as_posix().split("/")

    if "laws" in parts:
        return "legal"
    if "banking" in parts:
        return "banking"
    if "research" in parts:
        return "tech"

    if suffix in [".py", ".rs", ".js", ".ts"]:
        return "code_review"
    if suffix in [".md", ".txt", ".docx", ".pdf", ".yaml", ".yml"]:
        return "document"

    return "document"


def detect_tasks_from_content(content: str) -> List[str]:
    """ÙƒØ´Ù Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ù†ÙØ³Ù‡ (ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙƒØ«Ø± Ù…Ù† ØªØ®ØµØµ)."""

    lowered = content.lower()
    tasks: List[str] = []

    # Ù…Ø¤Ø´Ø±Ø§Øª Ø¨Ø±Ù…Ø¬ÙŠØ©
    if any(keyword in lowered for keyword in [
        "def ",
        "class ",
        "import ",
        "console.log",
        "fn ",
        "pub ",
        "async ",
        "await ",
    ]):
        tasks.append("code_review")

    # Ù…Ø¤Ø´Ø±Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
    if any(word in lowered for word in [
        "Ù†Ø¸Ø§Ù…",
        "Ù„Ø§Ø¦Ø­Ø©",
        "Ù‚Ø§Ù†ÙˆÙ†",
        "ØªØ´Ø±ÙŠØ¹",
        "Ù…Ø§Ø¯Ø© ",
        "Ù…Ø­ÙƒÙ…Ø©",
        "Ø¯Ø¹ÙˆÙ‰",
        "Ø¹Ù‚Ø¯",
        "Ø§ØªÙØ§Ù‚ÙŠØ©",
    ]):
        tasks.append("legal")

    # Ù…Ø¤Ø´Ø±Ø§Øª Ù…ØµØ±ÙÙŠØ© / Ø§Ù…ØªØ«Ø§Ù„
    if any(word in lowered for word in [
        "kyc",
        "aml",
        "pii",
        "gdpr",
        "Ù…Ø¹Ø§Ù…Ù„Ø©",
        "Ø­Ø³Ø§Ø¨",
        "Ø±ØµÙŠØ¯",
        "Ù…Ø®Ø§Ø·Ø± ØªØ´ØºÙŠÙ„ÙŠØ©",
        "Ø§Ø¦ØªÙ…Ø§Ù†",
        "Ø¹Ù…ÙŠÙ„",
        "transfers",
        "swift",
    ]):
        tasks.append("banking")

    # Ù…Ø¤Ø´Ø±Ø§Øª ØªÙ‚Ù†ÙŠØ© Ø­Ø¯ÙŠØ«Ø©
    if any(word in lowered for word in [
        "ai",
        "ml",
        "llm",
        "neural",
        "cloud",
        "kubernetes",
        "docker",
        "cyber",
        "zero trust",
        "space",
        "satellite",
    ]):
        tasks.append("tech")

    # Ù…Ø¤Ø´Ø±Ø§Øª Ø·Ø¨ÙŠØ©
    if any(word in lowered for word in [
        "mayo clinic",
        "nih",
        "who",
        "ØªØ´Ø®ÙŠØµ",
        "Ø£Ø¹Ø±Ø§Ø¶",
        "Ø¯ÙˆØ§Ø¡",
        "Ø¹Ù„Ø§Ø¬",
        "Ø³Ø±Ø·Ø§Ù†",
        "Ø¶ØºØ·",
        "Ø³ÙƒØ±",
        "diabetes",
        "hypertension",
    ]):
        tasks.append("medical")

    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø£ÙŠ Ù…Ø¤Ø´Ø±ØŒ Ù†Ø³ØªØ®Ø¯Ù… document ÙƒÙ…Ù‡Ù…Ø© Ø¹Ø§Ù…Ø©
    if not tasks:
        tasks.append("document")

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨
    unique_tasks: List[str] = []
    for t in tasks:
        if t not in unique_tasks:
            unique_tasks.append(t)
    return unique_tasks


def guess_language_from_extension(path_str: str) -> str:
    suffix = Path(path_str).suffix.lower()
    mapping = {
        ".py": "Python",
        ".rs": "Rust",
        ".js": "JavaScript",
        ".ts": "TypeScript",
        ".yaml": "YAML",
        ".yml": "YAML",
        ".md": "Markdown",
    }
    return mapping.get(suffix, "ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©")


# â€”â€“ Ù…Ø²ÙˆØ¯Ùˆ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ â€”â€“


def call_openai(system_prompt: str, user_content: str) -> str:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·.")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        "temperature": 0.2,
        "max_tokens": 1200,
    }
    response = requests.post(url, headers=headers, json=payload, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data["choices"][0]["message"]["content"]


def call_groq(system_prompt: str, user_content: str) -> str:
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        raise RuntimeError("GROQ_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·.")
    model = os.getenv("GROQ_MODEL", "mixtral-8x7b-32768")

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        "temperature": 0.2,
        "max_tokens": 1200,
    }
    response = requests.post(url, headers=headers, json=payload, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data["choices"][0]["message"]["content"]


def call_azure(system_prompt: str, user_content: str) -> str:
    api_key = os.getenv("AZURE_OPENAI_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    if not api_key or not endpoint or not deployment:
        raise RuntimeError("Ù…ØªØºÙŠØ±Ø§Øª Azure OpenAI ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© (AZURE_OPENAI_KEY/ENDPOINT/DEPLOYMENT).")

    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    url = f"{endpoint}/openai/deployments/{deployment}/chat/completions?api-version={api_version}"

    headers = {
        "api-key": api_key,
        "Content-Type": "application/json",
    }
    payload = {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        "temperature": 0.2,
        "max_tokens": 1200,
    }
    response = requests.post(url, headers=headers, json=payload, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data["choices"][0]["message"]["content"]


def call_local(system_prompt: str, user_content: str) -> str:
    """Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠ (Ù…Ø«Ù„ Phi-3) Ø¹Ø¨Ø± Ø®Ø§Ø¯Ù… HTTP Ø¯Ø§Ø®Ù„ÙŠ."""

    endpoint = os.getenv("LOCAL_MODEL_ENDPOINT")
    if not endpoint:
        raise RuntimeError("LOCAL_MODEL_ENDPOINT ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· Ù„Ù…Ø²ÙˆØ¯ local.")

    headers = {"Content-Type": "application/json"}
    payload = {
        "system": system_prompt,
        "input": user_content,
    }
    response = requests.post(endpoint, headers=headers, json=payload, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data.get("output", "")


def call_model(system_prompt: str, user_content: str) -> str:
    provider = os.getenv("PROVIDER", "openai").lower()
    if provider == "openai":
        return call_openai(system_prompt, user_content)
    if provider == "groq":
        return call_groq(system_prompt, user_content)
    if provider == "azure":
        return call_azure(system_prompt, user_content)
    if provider == "local":
        return call_local(system_prompt, user_content)

    raise ValueError(f"Ù…Ø²ÙˆØ¯ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {provider}")


# â€”â€“ Ø¨Ù†Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… â€”â€“


def build_user_content(task: str, content: str, filename: str | None) -> str:
    """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø±Ø³Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§."""

    if task == "code_review":
        lang = guess_language_from_extension(filename or "")
        return (
            f"Ø§Ù„Ù…Ù„Ù: {filename or 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}\n"
            f"Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: {lang}\n\n"
            "Ø§Ù„ÙƒÙˆØ¯:\n"
            f"{content}\n"
        )

    header = f"Ø§Ù„Ù…Ù„Ù: {filename}\n\n" if filename else ""
    return header + content


# â€”â€“ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€Gateway Ø¹Ù„Ù‰ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ â€”â€“


def run_gateway_on_file(file_path: str, task_mode: str = "auto") -> str:
    """ÙŠØ´ØºÙ‘Ù„ Ø§Ù„Ù€Gateway Ø¹Ù„Ù‰ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙˆÙŠØ¹ÙŠØ¯ Ù†Øµ Markdown Ø¬Ø§Ù‡Ø²."""

    path = Path(file_path)
    if not path.is_file():
        raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")

    raw_content = read_file_smart(file_path)

    if task_mode == "auto":
        base_task = guess_task_from_path(file_path)
        detected_tasks = detect_tasks_from_content(raw_content)

        if base_task not in detected_tasks:
            detected_tasks.insert(0, base_task)

        tasks: List[str] = []
        for detected in detected_tasks:
            if detected not in tasks:
                tasks.append(detected)
    else:
        tasks = [task_mode]

    sections: List[str] = []
    sections.append(f"## ğŸ“„ Ø§Ù„Ù…Ù„Ù: `{file_path}`\n")

    for task in tasks:
        try:
            system_prompt = load_prompt(task)
        except Exception as exc:  # noqa: BLE001
            sections.append(f"### âš ï¸ Ø§Ù„Ù…Ù‡Ù…Ø©: `{task}`\n\nØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€prompt: {exc}\n")
            continue

        user_content = build_user_content(task, raw_content, file_path)

        try:
            model_output = call_model(system_prompt, user_content)
        except Exception as exc:  # noqa: BLE001
            sections.append(f"### âš ï¸ Ø§Ù„Ù…Ù‡Ù…Ø©: `{task}`\n\nÙØ´Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {exc}\n")
            continue

        sections.append(f"### ğŸ§  Ø§Ù„Ù…Ù‡Ù…Ø©: `{task}`\n\n{model_output}\n")

    sections.append("\n---\n")
    return "\n".join(sections)


# â€”â€“ CLI â€”â€“


def main() -> None:
    parser = argparse.ArgumentParser(description="AI Gateway V3")
    parser.add_argument(
        "--task",
        type=str,
        default="auto",
        help="Ù…Ù‡Ù…Ø© Ù…Ø­Ø¯Ø¯Ø© (code_review, legal, medical, tech, banking, document) Ø£Ùˆ auto Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù‡Ø§Ù… ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.",
    )
    parser.add_argument(
        "--file",
        type=str,
        required=True,
        help="Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡.",
    )

    args = parser.parse_args()

    markdown_result = run_gateway_on_file(args.file, task_mode=args.task)
    print(markdown_result)


if __name__ == "__main__":
    main()
