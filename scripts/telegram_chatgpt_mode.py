#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
telegram_chatgpt_mode.py

Ø¨ÙˆØª ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…ØªÙ‚Ø¯Ù… ÙŠØ¹Ù…Ù„ ÙƒÙ€ ChatGPT Ø¯Ø§Ø®Ù„ Ù…Ø³ØªÙˆØ¯Ø¹ Top-TieR-Global-HUB-AI
- /chat        : Ø¯Ø±Ø¯Ø´Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù…Ø¹ Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
- /repo        : ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ø§Ø±ÙŠØ± ULTRA + ARCHITECTURE
- /insights    : Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ Ø¹Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
- /file        : ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø¯Ø¦ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©
- /status      : Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
- /help        : Ù…Ø³Ø§Ø¹Ø¯Ø©
- /whoami      : Ù…Ø¹Ø±ÙØ© Telegram ID Ù„Ø¥Ø¶Ø§ÙØªÙ‡ ÙÙŠ Allowlist

ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø£Ø³Ø±Ø§Ø±:
- TELEGRAM_BOT_TOKEN
- TELEGRAM_ALLOWLIST
- OPENAI_API_KEY
- OPENAI_MODEL (Ù…Ø·Ù„ÙˆØ¨ØŒ Ù…Ø«Ø§Ù„: gpt-4o-mini)
- GITHUB_REPO (Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·)
- ULTRA_PREFLIGHT_PATH / FULL_SCAN_SCRIPT / LOG_FILE_PATH (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ø¯Ù…Ø¬ Ø£Ø¹Ù…Ù‚)
"""

import os
import sys
import json
import logging
import textwrap
import subprocess
from pathlib import Path
from typing import Dict, List, Any

import requests
from telegram import Update, Document
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# Load .env file
from dotenv import load_dotenv
load_dotenv()

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„ ----------------------
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger("telegram_chatgpt_mode")

# ---------------------- Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© ----------------------
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
ALLOWLIST_ENV = os.getenv("TELEGRAM_ALLOWLIST", "").strip()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

GITHUB_REPO = os.getenv("GITHUB_REPO", "MOTEB1989/Top-TieR-Global-HUB-AI")

ULTRA_PREFLIGHT_PATH = os.getenv("ULTRA_PREFLIGHT_PATH", "scripts/ultra_preflight.sh")
FULL_SCAN_SCRIPT = os.getenv("FULL_SCAN_SCRIPT", "scripts/execute_full_scan.sh")
LOG_FILE_PATH = os.getenv("LOG_FILE_PATH", "analysis/ULTRA_REPORT.md")

CHAT_HISTORY_PATH = Path(os.getenv("CHAT_HISTORY_PATH", "analysis/chat_sessions.json"))
CHAT_HISTORY_PATH.parent.mkdir(parents=True, exist_ok=True)

# ---------------------- Validation ----------------------
# Validate critical environment variables (should be done by verify_env.py in deployment)
if not OPENAI_MODEL:
    logger.error("âŒ OPENAI_MODEL is required but not set!")
    logger.error("Please run: python scripts/verify_env.py to validate your configuration")
    sys.exit(1)

# ---------------------- Allowlist ----------------------
def parse_allowlist(raw: str):
    if not raw:
        return set()
    parts = [p.strip() for p in raw.split(",") if p.strip()]
    ids = set()
    for p in parts:
        try:
            ids.add(int(p))
        except ValueError:
            continue
    return ids

USER_ALLOWLIST = parse_allowlist(ALLOWLIST_ENV)


def is_authorized(update: Update) -> bool:
    """ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¶Ù…Ù† Ø§Ù„Ù€ Allowlist (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± ÙØ§Ø±ØºØ©)."""
    if not USER_ALLOWLIST:
        # Ø¥Ø°Ø§ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©: Ù†Ø³Ù…Ø­ Ù„Ù„Ø¬Ù…ÙŠØ¹ (ÙˆÙŠÙ…ÙƒÙ† Ù„Ø§Ø­Ù‚Ø§Ù‹ ØªØ´Ø¯ÙŠØ¯Ù‡Ø§)
        return True
    uid = update.effective_user.id if update.effective_user else None
    return uid in USER_ALLOWLIST


async def reject_if_unauthorized(update: Update) -> bool:
    if is_authorized(update):
        return False
    await update.message.reply_text(
        "âŒ ØºÙŠØ± Ù…ØµØ±Ø­ Ù„Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±.\n"
        "Ø§Ø³ØªØ®Ø¯Ù… /whoami Ø«Ù… Ø§Ø·Ù„Ø¨ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø±ÙÙƒ Ø¥Ù„Ù‰ TELEGRAM_ALLOWLIST."
    )
    return True


# ---------------------- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø§Ù„ØªØ§Ø±ÙŠØ®) ----------------------
def load_sessions() -> Dict[str, List[Dict[str, str]]]:
    if not CHAT_HISTORY_PATH.exists():
        return {}
    try:
        with CHAT_HISTORY_PATH.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.warning("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ØªØ§Ø±ÙŠØ®: %s", e)
        return {}


def save_sessions(sessions: Dict[str, List[Dict[str, str]]]) -> None:
    try:
        with CHAT_HISTORY_PATH.open("w", encoding="utf-8") as f:
            json.dump(sessions, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error("ÙØ´Ù„ Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„ØªØ§Ø±ÙŠØ®: %s", e)


def get_user_key(update: Update) -> str:
    uid = update.effective_user.id if update.effective_user else 0
    uname = update.effective_user.username or ""
    return f"{uid}:{uname}"


def append_message(
    sessions: Dict[str, List[Dict[str, str]]],
    user_key: str,
    role: str,
    content: str,
    max_messages: int = 30,
) -> None:
    if user_key not in sessions:
        sessions[user_key] = []
    sessions[user_key].append({"role": role, "content": content})
    # Ù‚ØµÙ‘ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¶Ø®Ù…
    if len(sessions[user_key]) > max_messages:
        sessions[user_key] = sessions[user_key][-max_messages:]


# ---------------------- Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI ----------------------
class OpenAIError(Exception):
    pass


def call_openai_chat(
    messages: List[Dict[str, str]],
    model: str = None,
    temperature: float = 0.4,
    max_tokens: int = 700,
) -> str:
    if not OPENAI_API_KEY:
        raise OpenAIError("OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©")

    model = model or OPENAI_MODEL
    url = f"{OPENAI_BASE_URL.rstrip('/')}/chat/completions"

    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }

    resp = requests.post(url, json=payload, headers=headers, timeout=60)
    if resp.status_code != 200:
        logger.error("Ø®Ø·Ø£ Ù…Ù† OpenAI: %s - %s", resp.status_code, resp.text[:500])
        raise OpenAIError(f"OpenAI error {resp.status_code}: {resp.text[:200]}")

    data = resp.json()
    try:
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        logger.error("Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø© Ù…Ù† OpenAI: %s | %s", e, data)
        raise OpenAIError("Unexpected OpenAI response structure")


def make_system_prompt() -> str:
    return textwrap.dedent(
        f"""
        Ø£Ù†Øª ÙˆÙƒÙŠÙ„ Ø°ÙƒÙŠ ÙŠØ¹Ù…Ù„ Ø¯Ø§Ø®Ù„ Ù…Ø³ØªÙˆØ¯Ø¹ GitHub Ø¨Ø§Ø³Ù… {GITHUB_REPO}.
        Ø¯ÙˆØ±Ùƒ:
        - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø«Ù„ ChatGPT Ù„ÙƒÙ† Ù…Ø¹ ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰:
          â€¢ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
          â€¢ Ø§Ù„Ø£Ù…Ù† ÙˆØ§Ù„Ø­ÙÙˆÙ’ÙƒÙ…Ø©
          â€¢ Ø§Ù„Ø£ØªÙ…ØªØ© (Agents / Workflows)
          â€¢ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„Ù€ CI/CD
        - Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨ Ù…Ø­ØªØ±ÙØŒ Ù…Ø®ØªØµØ±ØŒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ù…Ø§ Ù„Ù… ÙŠÙØ·Ù„Ø¨ ØºÙŠØ± Ø°Ù„Ùƒ.
        - Ø¹Ù†Ø¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ØŒ Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù† ØªÙˆÙØ±:
          â€¢ ARCHITECTURE.md
          â€¢ SECURITY_POSTURE.md
          â€¢ AGENT_PLAYBOOK.md
          â€¢ WORKFLOW_MAP.md
          â€¢ ULTRA_REPORT.md
        - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©: Ù‚Ù„ Ø¨ÙˆØ¶ÙˆØ­ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©" Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØ®Ù…ÙŠÙ†.
        """
    ).strip()


# ---------------------- Ø£Ø¯ÙˆØ§Øª (Tools) ----------------------
def run_local_script(cmd: str) -> str:
    """ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±Ø¨Øª Ù…Ø­Ù„ÙŠ (Ù…Ø«Ù„ preflight Ø£Ùˆ scan) ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª."""
    try:
        out = subprocess.check_output(
            cmd,
            shell=True,
            stderr=subprocess.STDOUT,
            encoding="utf-8",
            timeout=300,
        )
        return out[:3500]
    except subprocess.CalledProcessError as e:
        return f"âŒ ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±:\n{cmd}\n\nØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\n{e.output[:2000]}"
    except Exception as e:
        return f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±:\n{cmd}\n{e}"


def read_small_file(path: str, max_chars: int = 4000) -> str:
    p = Path(path)
    if not p.exists():
        return f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path}"
    try:
        txt = p.read_text(encoding="utf-8", errors="ignore")
        if len(txt) > max_chars:
            return txt[:max_chars] + "\n...\n[ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰]"
        return txt
    except Exception as e:
        return f"âŒ ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {path}: {e}"


def build_repo_context() -> str:
    """Ø¬Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©/Ø§Ù„Ø£Ù…Ù†/Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±."""
    parts = []
    candidates = [
        "ARCHITECTURE.md",
        "SECURITY_POSTURE.md",
        "AGENT_PLAYBOOK.md",
        "WORKFLOW_MAP.md",
        "analysis/ULTRA_REPORT.md",
        "README.md",
    ]
    for path in candidates:
        if Path(path).exists():
            parts.append(f"\n===== {path} =====\n")
            parts.append(read_small_file(path, max_chars=2500))
    if not parts:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù‡Ù†Ø¯Ø³ÙŠØ©/Ø£Ù…Ù†ÙŠØ© ÙƒØ§ÙÙŠØ© Ù„ØªÙ…Ø«ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹."
    return "\n".join(parts)


# ---------------------- Ø£ÙˆØ§Ù…Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ----------------------
HELP_TEXT = textwrap.dedent(
    """
    ğŸ¤– *ÙˆØ¶Ø¹ ChatGPT Ù…ØªÙ‚Ø¯Ù… â€“ Top-TieR-Global-HUB-AI*

    Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:

    /start      â†’ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨
    /help       â†’ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
    /whoami     â†’ Ø¹Ø±Ø¶ Telegram ID Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ø§Ù„Ù€ Allowlist

    ğŸ’¬ ÙˆØ¶Ø¹ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©:
    /chat Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„...
      â€¢ Ø¯Ø±Ø¯Ø´Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù…Ø¹ Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
      â€¢ Ù…Ø«Ø§Ù„: `/chat Ù…Ø§ Ù‡ÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ØŸ`

    ğŸ§  ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©:
    /repo
      â€¢ ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ ARCHITECTURE/SECURITY/ULTRA_REPORT
    /insights
      â€¢ Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ Ø¹Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ (Ù…Ø®Ø§Ø·Ø±ØŒ ÙØ±Øµ ØªØ­Ø³ÙŠÙ†ØŒ Ø£ÙˆÙ„ÙˆÙŠØ§Øª)

    ğŸ“‚ ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª:
    Ø£Ø±Ø³Ù„ Ù…Ù„ÙØ§Ù‹ Ù†ØµÙŠØ§Ù‹ (txt/md/json/log) Ø£Ùˆ Ø³ÙƒØ±Ø¨ØªØŒ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø¯Ø¦ÙŠ Ù„Ù‡.

    âš™ï¸ Ø­Ø§Ù„Ø© ØªØ´ØºÙŠÙ„:
    /status
      â€¢ Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙƒÙˆÙŠÙ† (OpenAI, GitHub, Allowlist)

    âš ï¸ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª:
    - Ø¨Ø¹Ø¶ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù…ØªØ§Ø­Ø© ÙÙ‚Ø· Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¯Ø§Ø®Ù„ Allowlist (TELEGRAM_ALLOWLIST).
    """
).strip()


async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "ğŸ¤– Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ÙˆØ¶Ø¹ ChatGPT Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¯Ø§Ø®Ù„ Ù…Ø³ØªÙˆØ¯Ø¹ Top-TieR-Global-HUB-AI.\n"
        "Ø§Ø³ØªØ®Ø¯Ù… /help Ù„Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©."
    )


async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_markdown(HELP_TEXT)


async def cmd_whoami(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    uid = update.effective_user.id if update.effective_user else "N/A"
    uname = update.effective_user.username if update.effective_user else ""
    await update.message.reply_text(
        f"ğŸ†” Ù…Ø¹Ø±ÙÙƒ ÙÙŠ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…: `{uid}`\n"
        f"ğŸ‘¤ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: @{uname}\n\n"
        "Ø£Ø¶Ù Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ø±Ù ÙÙŠ TELEGRAM_ALLOWLIST (ÙƒÙ…Ø«Ø§Ù„):\n"
        f"TELEGRAM_ALLOWLIST={uid}"
    )


async def cmd_status(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    parts = []

    parts.append("ğŸ“Š *Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… â€“ ChatGPT Mode*")
    parts.append(f"- Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹: `{GITHUB_REPO}`")

    # OpenAI
    if OPENAI_API_KEY:
        parts.append("ğŸ§  OpenAI: âœ… Ù…Ø¶Ø¨ÙˆØ· (OPENAI_API_KEY Ù…ÙˆØ¬ÙˆØ¯)")
        parts.append(f"   â€¢ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: `{OPENAI_MODEL}`")
    else:
        parts.append("ğŸ§  OpenAI: âŒ Ù…ÙÙ‚ÙˆØ¯ (OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯)")

    # Allowlist
    if USER_ALLOWLIST:
        parts.append("ğŸ” Allowlist: âœ… Ù…ÙØ¹Ù‘Ù„")
        parts.append("   â€¢ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù…ØµØ±Ø­ Ù„Ù‡Ù…:")
        for uid in USER_ALLOWLIST:
            parts.append(f"     - {uid}")
    else:
        parts.append("ğŸ” Allowlist: âš ï¸ ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ (Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©ØŒ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ø³Ù…ÙˆØ­ Ù„Ù‡Ù… Ø­Ø§Ù„ÙŠØ§Ù‹)")

    # Ù…Ù„ÙØ§Øª Ù‡Ù†Ø¯Ø³ÙŠØ©
    exist_flags = []
    for p in ["ARCHITECTURE.md", "SECURITY_POSTURE.md", "AGENT_PLAYBOOK.md", "WORKFLOW_MAP.md", "analysis/ULTRA_REPORT.md"]:
        if Path(p).exists():
            exist_flags.append(f"   â€¢ âœ… {p}")
        else:
            exist_flags.append(f"   â€¢ âŒ {p}")
    parts.append("ğŸ“‚ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©/Ø§Ù„Ø£Ù…Ù†:")
    parts.extend(exist_flags)

    await update.message.reply_markdown("\n".join(parts))


async def cmd_chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await reject_if_unauthorized(update):
        return

    if not OPENAI_API_KEY:
        await update.message.reply_text("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… /chat Ù„Ø£Ù† OPENAI_API_KEY ØºÙŠØ± Ù…Ù‡ÙŠØ£.")
        return

    if not context.args:
        await update.message.reply_text(
            "âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±.\n"
            "Ù…Ø«Ø§Ù„:\n"
            "/chat Ù…Ø§ Ù‡ÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ù€ CI/CD ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ØŸ"
        )
        return

    user_question = " ".join(context.args).strip()
    user_key = get_user_key(update)

    sessions = load_sessions()
    append_message(sessions, user_key, "user", user_question)

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ø¹ System Prompt + ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    messages = [{"role": "system", "content": make_system_prompt()}]
    messages.extend(sessions[user_key])

    try:
        reply = call_openai_chat(messages)
    except OpenAIError as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:\n{e}")
        return

    append_message(sessions, user_key, "assistant", reply)
    save_sessions(sessions)

    # ØªÙ‚Ø·ÙŠØ¹ Ø§Ù„Ø±Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
    if len(reply) > 3500:
        reply = reply[:3500] + "\n...\n[ØªÙ… Ù‚Ø·Ø¹ Ø§Ù„Ø±Ø¯ Ù„Ø·ÙˆÙ„Ù‡]"

    await update.message.reply_text(reply)


async def cmd_repo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await reject_if_unauthorized(update):
        return

    context_text = build_repo_context()

    if not OPENAI_API_KEY:
        # Ø¥Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ OpenAIØŒ Ù†Ø¹ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù…
        await update.message.reply_text(
            "âš ï¸ OPENAI_API_KEY ØºÙŠØ± Ù…Ù‡ÙŠØ£ØŒ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø©:\n\n"
            + context_text[:3500]
        )
        return

    prompt = textwrap.dedent(
        """
        Ø­Ù„Ù‘Ù„ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆÙ‚Ø¯Ù…:
        - Ù…Ù„Ø®Øµ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ (High-level summary)
        - Ø£Ø¨Ø±Ø² Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø£Ùˆ Ø§Ù„Ø£Ù…Ù†ÙŠØ©
        - Ø£Ù‡Ù… Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©
        - 3 ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù‚ØµÙŠØ±Ø©

        Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹:
        """
    ).strip()

    messages = [
        {"role": "system", "content": make_system_prompt()},
        {"role": "user", "content": prompt + "\n\n" + context_text},
    ]

    try:
        reply = call_openai_chat(messages, max_tokens=700)
    except OpenAIError as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹:\n{e}")
        return

    await update.message.reply_text(reply[:3500])


async def cmd_insights(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await reject_if_unauthorized(update):
        return

    context_text = build_repo_context()

    if not OPENAI_API_KEY:
        await update.message.reply_text(
            "âš ï¸ OPENAI_API_KEY ØºÙŠØ± Ù…Ù‡ÙŠØ£ØŒ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø®Ø§Ù… ÙÙ‚Ø·:\n\n"
            + context_text[:3500]
        )
        return

    prompt = textwrap.dedent(
        """
        ØªØµØ±Ù ÙƒÙ…Ù‡Ù†Ø¯Ø³ Ø¨Ø±Ù…Ø¬ÙŠØ§Øª Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ù…Ù†ØµØ© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
        Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ØŒ Ø£Ø¹Ø·Ù†ÙŠ:

        1) Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Current State)
        2) Ø£Ù‡Ù… 5 Ù…Ø®Ø§Ø·Ø± Ø£Ùˆ ÙØ¬ÙˆØ§Øª (Risks / Gaps)
        3) Ø®Ø·Ø© ØªÙ†ÙÙŠØ° Ù…Ù† 3 Ù…Ø±Ø§Ø­Ù„ (Ù‚ØµÙŠØ±Ø©ØŒ Ù…ØªÙˆØ³Ø·Ø©ØŒ Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ø£Ø¬Ù„)
        4) Ø£ÙŠ ØªØ­Ø°ÙŠØ± ÙŠØ¬Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù„Ù‡

        Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù‚Ø³Ù‘Ù…Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ø¶Ø­Ø© ÙˆÙ†Ù‚Ø§Ø·.
        """
    ).strip()

    messages = [
        {"role": "system", "content": make_system_prompt()},
        {"role": "user", "content": prompt + "\n\nØ³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹:\n" + context_text},
    ]

    try:
        reply = call_openai_chat(messages, max_tokens=900)
    except OpenAIError as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù€ Insights:\n{e}")
        return

    await update.message.reply_text(reply[:3500])


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…Ù„Ù Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªØ­Ù„ÙŠÙ„Ù‡ Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹."""
    if await reject_if_unauthorized(update):
        return

    message = update.message
    doc: Document = message.document
    if not doc:
        return

    # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹
    try:
        file = await doc.get_file()
        tmp_path = Path("analysis/uploads")
        tmp_path.mkdir(parents=True, exist_ok=True)
        local_file = tmp_path / f"{doc.file_unique_id}_{doc.file_name}"
        await file.download_to_drive(str(local_file))
    except Exception as e:
        await message.reply_text(f"âŒ ØªØ¹Ø°Ø± ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…: {e}")
        return

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
    suffix = local_file.suffix.lower()
    text_content = ""
    if suffix in [".txt", ".md", ".log", ".json", ".yaml", ".yml", ".py", ".ts", ".sh"]:
        try:
            text_content = local_file.read_text(encoding="utf-8", errors="ignore")
        except Exception as e:
            await message.reply_text(f"âš ï¸ ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØŒ Ù„ÙƒÙ† ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡ØªÙ‡ ÙƒÙ†Øµ: {e}")
            return
    else:
        await message.reply_text(
            f"ğŸ“ ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {local_file.name}\n"
            f"Ø§Ù„Ù†ÙˆØ¹: {suffix or 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}\n\n"
            "Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ø§ Ø£Ø¯Ø¹Ù… Ø¥Ù„Ø§ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© (txt, md, log, json, yaml, py, ts, sh)."
        )
        return

    # Ø¥Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ OpenAI: Ù†Ø¹ÙŠØ¯ Ù…Ù‚ØªØ·Ù ÙÙ‚Ø·
    if not OPENAI_API_KEY:
        snippet = text_content[:1500]
        await message.reply_text(
            "âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ OPENAI_API_KEYØŒ Ø³Ø£Ø¹Ø±Ø¶ Ù…Ù‚ØªØ·ÙØ§Ù‹ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù:\n\n" + snippet
        )
        return

    prompt = textwrap.dedent(
        f"""
        ØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù Ù…Ù† Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø±Ù…Ø¬ÙŠ.

        Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
        - Ø£Ø¹Ø·Ù†ÙŠ Ù…Ù„Ø®ØµØ§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
        - Ø¥Ù† ÙƒØ§Ù† Ø³ÙƒØ±Ø¨Øª Ø£Ùˆ ÙƒÙˆØ¯: ÙˆØ¶Ù‘Ø­ Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙØ¹Ù„Ù‡
        - Ø¥Ù† ÙƒØ§Ù† ØªÙƒÙˆÙŠÙ† (config): ÙˆØ¶Ù‘Ø­ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø£Ùˆ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        - Ù„Ø§ ØªØ®Ù…Ù† Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù†Øµ ÙˆØ§Ø¶Ø­Ø§Ù‹ØŒ ÙˆÙ‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©" Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©

        Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù (Ù…Ù‚ØªØ·Ù):
        """
    ).strip()

    snippet = text_content[:4000]
    messages = [
        {"role": "system", "content": make_system_prompt()},
        {"role": "user", "content": prompt + "\n\n" + snippet},
    ]

    try:
        reply = call_openai_chat(messages, max_tokens=700)
    except OpenAIError as e:
        await message.reply_text(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù:\n{e}")
        return

    await message.reply_text(reply[:3500])


async def fallback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø±Ø³Ø§Ø¦Ù„ Ù†ØµÙŠØ© Ù„Ø§ ØªØ¨Ø¯Ø£ Ø¨Ø£Ù…Ø± /."""
    text = update.message.text or ""
    if not text.strip():
        return

    # ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ ÙƒØ±Ø³Ø§Ù„Ø© Ø¯Ø±Ø¯Ø´Ø© Ù‚ØµÙŠØ±Ø©
    if not OPENAI_API_KEY:
        await update.message.reply_text(
            "ğŸ“¨ Ø§Ø³ØªÙ„Ù…Øª Ø±Ø³Ø§Ù„ØªÙƒØŒ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙˆØ¬Ø¯ OPENAI_API_KEY Ø­Ø§Ù„ÙŠØ§Ù‹.\n"
            "Ø§Ø³ØªØ®Ø¯Ù… /help Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©."
        )
        return

    user_key = get_user_key(update)
    sessions = load_sessions()
    append_message(sessions, user_key, "user", text.strip())

    messages = [{"role": "system", "content": make_system_prompt()}]
    messages.extend(sessions[user_key])

    try:
        reply = call_openai_chat(messages, max_tokens=500)
    except OpenAIError as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©:\n{e}")
        return

    append_message(sessions, user_key, "assistant", reply)
    save_sessions(sessions)

    await update.message.reply_text(reply[:3500])


# ---------------------- main ----------------------
def main() -> None:
    if not TELEGRAM_TOKEN:
        raise RuntimeError("âŒ TELEGRAM_BOT_TOKEN ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©")

    logger.info("Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Telegram ChatGPT Mode Bot ...")
    logger.info("Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹: %s", GITHUB_REPO)
    if USER_ALLOWLIST:
        logger.info("Allowlist Ù…ÙØ¹Ù‘Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: %s", USER_ALLOWLIST)
    else:
        logger.warning("Allowlist ÙØ§Ø±Øº - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ø³Ù…ÙˆØ­ Ù„Ù‡Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.")

    app = Application.builder().token(TELEGRAM_TOKEN).build()

    # Ø£ÙˆØ§Ù…Ø±
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("help", cmd_help))
    app.add_handler(CommandHandler("whoami", cmd_whoami))
    app.add_handler(CommandHandler("status", cmd_status))
    app.add_handler(CommandHandler("chat", cmd_chat))
    app.add_handler(CommandHandler("repo", cmd_repo))
    app.add_handler(CommandHandler("insights", cmd_insights))

    # Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…Ù„ÙØ§Øª
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    # fallback Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
    app.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, fallback_handler)
    )

    app.run_polling()


if __name__ == "__main__":
    main()
